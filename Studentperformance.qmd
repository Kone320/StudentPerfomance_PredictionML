---
title: "STUDENT PERFORMANCE ANALYSIS"
author: Arouna Romeo KONE
date: today
---

------------------------------------------------------------------------

# 0. SETUP

------------------------------------------------------------------------

```{r}
# Load necessary packages

packages <- c("dplyr", "ggplot2", "tidyr", "readr", "stringr", "GGally", "caret", "corrplot","randomForest","xgboost","factoextra","Metrics","yardstick", "pROC","knitr","kableExtra")
installed <- packages %in% installed.packages()
if(any(!installed)) install.packages(packages[!installed])
lapply(packages,library, character.only= TRUE)
```

```{r}
# Load dataset
data <- read.csv("/Users/konearounaromeo/Downloads/student-scores.csv")
```

------------------------------------------------------------------------

# 1. DEFINE THE OBJECTIVE

------------------------------------------------------------------------

#### Goal: Understand what factors impact student academic performance

#### Target variables: math_score, physics_score, bilogy_score, geography_score...

#### Questions:

#### - Are absences related to lower scores?

#### - Do self-study hours help?

#### - Are there differences by gender, job status, or extracurriculars?

------------------------------------------------------------------------

# 2. DATA CLEANING & PREPROCESSING

```{r}
# Drop non-useful personal columns
data <- data %>%
  select(-id, -first_name, -last_name, -email)
```

```{r}
# Check missing values
colSums(is.na(data))
```

```{r}
# Convert categorial variables to factors 
categorical_vars <- c('gender','part_time_job','extracurricular_activities','career_aspiration')
data[categorical_vars] <- lapply(data[categorical_vars], as.factor)
lapply(data[categorical_vars], levels)
```

```{r}
# Convert to long format for faceting
data_long <- pivot_longer(
  data[categorical_vars], 
  cols = everything(), 
  names_to = "variable", 
  values_to = "level"
)

# Plot all variables in one grid
ggplot(data_long, aes(x = level)) +
  geom_bar(fill = "steelblue") +
  facet_wrap(~variable, scales = "free") +
  labs(title = "Distribution of Categorical Variables") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  

```

------------------------------------------------------------------------

# 3. EXPLORATORY DATA ANALYSIS (EDA)

```{r}

freq <- lapply(data[categorical_vars], function(x) prop.table(table(x)))
print(freq)

```

```{r}
# Overview of the data
names(data)
glimpse(data)
summary(data)

```

```{r}
# Distribution of scores
score_vars <- names(data)[grepl('_score',names(data))]

for (var in score_vars) {
  p <- ggplot(data, aes(x = .data[[var]])) +
    geom_histogram(
      aes(y = after_stat(density)),bins = 20,fill = "steelblue",color = 'white') +
    geom_density(color = 'red', linewidth = 1) +
    theme_minimal() +
    ggtitle(paste('Distribution of:', var))
  
  print(p)
}

```

```{r}
# Count gender 
gender_count <- data %>% count(gender)
gender_count

```

```{r}
# Gender-based average scores
table_mean <- data %>%
  group_by(gender) %>%
  summarise(across(all_of(score_vars), mean, na.rm = TRUE))
print(table_mean)

```

```{r}
# Correlation between scores 

score_data <- data %>% select(all_of(score_vars))
corrplot(cor(score_data),method = "color",addCoef.col = "black",
col = colorRampPalette(c("darkred", "white", "darkgreen"))(100),
tl.cex = 0.8,
number.cex = 0.6,
mar = c(0, 0, 1, 0))

```

+:-----------------------------------------------------------------------------+
| ###### throught the corrplot there is no multicolinearity between the scores |
+------------------------------------------------------------------------------+

##### 

## Bivariate Analysis

```{r}
# Build average score for all score vars 

data <- data %>% mutate(average_score = rowMeans(select(.,all_of(score_vars))))

# Correlation with average score
data_corr <- cor(data[, c(score_vars, "average_score")])
cor_average <- data_corr["average_score", score_vars]
cor_average <- sort(abs(cor_average), decreasing = TRUE)
print(cor_average)
barplot(cor_average, las = 2, col = "tomato",
        main = "Correlation with average score")

```

###### 

Mathematics and biology scores are strongly corelated with the average score

```{r}
# Relationship between explanatory variables and performance

# Study time
ggplot(data, aes(x = weekly_self_study_hours, y = average_score)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "darkred") +
  theme_minimal() +
  labs(title = "Study time and average score")

```

```{r}
# Part-time job
ggplot(data, aes(x = part_time_job, y = average_score)) +
  geom_boxplot(fill = "lightblue") + theme_minimal() +
  labs(title = "Impact of part-time job", x = "Job", y = "Average score")

```

###### 

Those wo don't work at part time have better results (average score 82 vs 77)

```{r}
# Extracurricular activities
ggplot(data, aes(x = extracurricular_activities, y = average_score)) +
  geom_boxplot(fill = "lightgreen") + theme_minimal() +
  labs(title = "Extracurricular activities vs score")

```

```{r}
# Absences
ggplot(data, aes(x = absence_days, y = average_score)) +
  geom_point(alpha = 0.6) + geom_smooth(method = "lm", color = "purple") +
  theme_minimal() + labs(title = "Absences vs performance")

```

```{r}
# Career aspiration
library(forcats)
top_careers <- data %>% count(career_aspiration) %>% top_n(5, n) %>% pull(career_aspiration)
data %>%
  filter(career_aspiration %in% top_careers) %>%
  mutate(career_aspiration = fct_infreq(career_aspiration)) %>%
  ggplot(aes(x = career_aspiration, y = average_score)) +
  geom_boxplot(fill = "coral") + theme_minimal() +
  labs(title = "Average score by career aspiration") + coord_flip()

```

# 

4.  FEATURE ENGINEERING

```{r}
data <- data %>% mutate(
  high_achiever = as.factor(ifelse(average_score >= 85, 1, 0)),
  study_efficiency = average_score / (weekly_self_study_hours + 1) # The higher the study_efficiency score, the better the student's academic performance relative to their study time—indicating strong learning effectiveness.
)

```

```{r}
# To properly evaluate each model on unseen data

set.seed(42)

# Data spliting 
trainIndex <- createDataPartition(data$average_score,p=0.8,list=FALSE)
train <- data[trainIndex,]
test <- data[-trainIndex,]

# Display sizes of train and test sets
message("Training set size (rows, columns): ", paste(dim(train), collapse = ", "))  
message("Test set size (rows, columns): ", paste(dim(test), collapse = ", "))  
      

```

# 

5.  MODELING - REGRESSION

```{r}
#  Goal: Predict continuous variable (average_score)

# 5.1 Linear regression (baseline)
model_lm <- lm(average_score ~ gender + part_time_job + absence_days + weekly_self_study_hours + extracurricular_activities, data = train)
pred_lm <- predict(model_lm, test)
lm_metrics <- postResample(pred_lm, test$average_score)
lm_metrics

```

###### With an R² of 28.8%, your linear regression model explains only a small portion of the variation in students' average scores (0-100 scale).

The RMSE of 5.30 and MAE of 4.30 indicate that, on average, the model's predictions deviate by \~5 points from the actual scores, suggesting limited predictive accuracy—though this might still be meaningful in an educational context where many factors influence grades.

```{r}
# 5.2 Random Forest (robust non-linear model)
ctrl <- trainControl(method = "cv", number = 5)
tuned_rf <- train(
  average_score ~ .,
  data = train,
  method = "rf",
  trControl = ctrl,
  tuneLength = 5
)
pred_rf <- predict(tuned_rf, test)
rf_metrics <- postResample(pred_rf, test$average_score)
rf_metrics


```

###### With an RMSE of 1.74 and R² of 94%,

our Random Forest model predicts scores with an average error below 2 points, explaining nearly all variability in the data, indicating outstanding performance.

```{r}
# 5.3 XGBoost with cross-validation
train_matrix <- model.matrix(average_score ~ .  - career_aspiration, data = train)
test_matrix <- model.matrix(average_score ~ . - career_aspiration, data = test)
dtrain <- xgb.DMatrix(data = train_matrix, label = train$average_score)
dtest <- xgb.DMatrix(data = test_matrix, label = test$average_score)

xgb_cv <- xgb.cv(
  data = dtrain,
  nrounds = 100,
  objective = "reg:squarederror",
  nfold = 5,
  metrics = "rmse",
  verbose = 0
)

model_xgb <- xgboost(data = dtrain, nrounds = which.min(xgb_cv$evaluation_log$test_rmse_mean), objective = "reg:squarederror", verbose = 0)
pred_xgb <- predict(model_xgb, dtest)
xgb_metrics <- postResample(pred_xgb, test$average_score)
xgb_metrics

```

###### With an RMSE of 1.28 and R² of 95.9%, your XGBoost model predicts scores with an average error of \~1.3 points, capturing nearly all data variability, indicating exceptional performance.

# 6. MODELING - CLASSIFICATION

```{r}
#  Goal: Predict high achievers (high_achiever)

# 6.1 Logistic regression
model_logit <- glm(high_achiever ~ gender + part_time_job + absence_days + weekly_self_study_hours + extracurricular_activities, data = train, family = "binomial")
pred_logit <- predict(model_logit, test, type = "response")
class_logit <- ifelse(pred_logit > 0.5, 1, 0)
conf_matrix_logit <- confusionMatrix(as.factor(class_logit), test$high_achiever)
conf_matrix_logit

```

###### The logistic regression model achieves a reasonably good overall accuracy of 79.15%, but it is strongly biased toward the majority class (students who are not high achievers). The model identifies almost all low-performing students, as shown by the very high sensitivity (97.7%), but it fails to correctly recognize high achievers, with a very low specificity of only 20%. This indicates a clear class imbalance problem in the dataset. To improve the detection of high achievers, it would be advisable to apply class rebalancing techniques (such as SMOTE or class weighting) or to explore more flexible models such as Random Forests or Gradient Boosting.

```{r}
# 6.2 Random Forest - Classification
model_rf_class <- randomForest(high_achiever ~ ., data = train)
pred_rf_class <- predict(model_rf_class, test)
conf_matrix_rf <- confusionMatrix(pred_rf_class, test$high_achiever)
varImpPlot(model_rf_class)
conf_matrix_rf


```

###### 

The Random Forest classifier delivers a perfect performance on the test set, achieving an overall accuracy of 100% with a 95% confidence interval of (99.08%, 100%). Both sensitivity (100%) and specificity (100%) indicate that the model correctly identifies all students, whether they are high achievers or not, without any misclassification. The Kappa statistic of 1 further confirms the perfect agreement between predictions and actual outcomes. While these results suggest that the Random Forest model is extremely effective on this dataset, such flawless performance raises the possibility of overfitting, especially if the dataset is small or not very diverse. To validate robustness, it would be important to test the model with additional data, apply cross-validation, or compare with other algorithms.

```{r}
# 6.3 XGBoost classification
label_train <- as.numeric(as.character(train$high_achiever))
label_test <- as.numeric(as.character(test$high_achiever))
train_matrix_class <- model.matrix(high_achiever ~ . - average_score  - career_aspiration, data = train)
test_matrix_class <- model.matrix(high_achiever ~ . - average_score  - career_aspiration, data = test)
dtrain_class <- xgb.DMatrix(data = train_matrix_class, label = label_train)
dtest_class <- xgb.DMatrix(data = test_matrix_class, label = label_test)
model_xgb_class <- xgboost(data = dtrain_class, objective = "binary:logistic", nrounds = 50, verbose = 0)
pred_xgb_class <- predict(model_xgb_class, dtest_class)
xgb_class <- ifelse(pred_xgb_class > 0.5, 1, 0)
confusionMatrix(as.factor(xgb_class), test$high_achiever)


```

###### 

**The XGBoost model achieves a strong overall performance with an accuracy of 95.23% and a 95% confidence interval of (92.65%, 97.1%). The sensitivity (97.7%) indicates that the model correctly identifies almost all non–high achievers, while the specificity (87.4%) shows that it also performs well in detecting true high achievers. The Kappa statistic of 0.8662 reflects excellent agreement between predicted and actual outcomes. Compared to logistic regression, XGBoost demonstrates a much better balance between detecting both achievers and non-achievers, reducing the bias toward the majority class. Although it does not reach the perfect scores of the Random Forest, its performance is more realistic and less likely to result from overfitting. Overall, XGBoost provides a highly accurate and well-balanced classifier for predicting student achievement.**

# 

7.  UNSUPERVISED CLUSTERING

```{r}
#  Group students by similar profiles
cluster_data <- data %>% select(all_of(score_vars), weekly_self_study_hours, absence_days) %>% scale()

# Optimal cluster number (elbow, silhouette)
fviz_nbclust(cluster_data, kmeans, method = "wss")
fviz_nbclust(cluster_data, kmeans, method = "silhouette")

k_model <- kmeans(cluster_data, centers = 2)
fviz_cluster(k_model, data = cluster_data)

```

###### 

Interpretation of the clustering analysis

Using K-means clustering, we grouped students based on their: - academic scores - weekly self-study hours - absence days

To determine the optimal number of clusters, two methods were applied: 1. Elbow method: suggested that the curve starts flattening at k = 2, indicating that two clusters capture most of the variance. 2. Silhouette method: also supported k = 2, with a relatively high silhouette score, confirming that the clusters are well separated.

The final K-means model with 2 clusters produced a clear partition of students into two distinct groups.

From the cluster visualization: - Cluster 1: characterized by higher study engagement and stronger academic performance. - Cluster 2: characterized by higher absence rates and weaker scores.

Conclusion: This segmentation highlights meaningful differences in student profiles: 1. Some students are consistent, high-performing learners. 2. Others are more at risk due to lack of study time or higher absenteeism.

```{r}
# Hierarchical clustering
hclust_model <- hclust(dist(cluster_data), method = "ward.D2")
plot(hclust_model, labels = FALSE, hang = -1, main = "Hierarchical Clustering")



```

# 8. MODEL EVALUATION - REGRESSION & CLASSIFICATION

## 

REGRESSION - EVALUATION

```{r}
# Calculate metrics for each regression model

R2 <- function(pred, actual) {
  1 - sum((actual - pred)^2) / sum((actual - mean(actual))^2)
}

# List of prediction
predictions <- list(
  "Linear Regression" = pred_lm,
  "Random Forest"     = pred_rf,
  "XGBoost"           = pred_xgb
)

regression_metrics <- data.frame(
  Model = names(predictions),
  RMSE  = sapply(predictions, function(p) Metrics::rmse(test$average_score, p)),
  MAE   = sapply(predictions, function(p) Metrics::mae(test$average_score, p)),
  R2    = sapply(predictions, function(p) R2(p, test$average_score))
)

regression_metrics

regression_metrics %>%
  kable(format = "html", digits = 3, caption = "Regression Metrics for Models") %>%
  kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover", "condensed"))

```

## CLASSIFICATION - EVALUATION

```{r}
test_class <- test

# Logistic regression
pred_logit_prob <- predict(model_logit, test_class, type = "response")
pred_logit_class <- factor(ifelse(pred_logit_prob > 0.5, 1, 0), levels = c(0, 1))

logit_df <- tibble(
  truth = factor(test_class$high_achiever, levels = c(0,1)),
  estimate = pred_logit_class
)

logit_accuracy <- yardstick::accuracy(logit_df, truth = truth, estimate = estimate)$.estimate
logit_precision <- yardstick::precision(logit_df, truth = truth, estimate = estimate)$.estimate
logit_recall <- yardstick::recall(logit_df, truth = truth, estimate = estimate)$.estimate
logit_f1 <- yardstick::f_meas(logit_df, truth = truth, estimate = estimate)$.estimate

roc_logit <- roc(test_class$high_achiever, pred_logit_prob)
auc_logit <- auc(roc_logit)

# Random Forest
pred_rf_class <- predict(model_rf_class, test_class)
prob_rf_class <- predict(model_rf_class, test_class, type = "prob")

rf_df <- tibble(
  truth = factor(test_class$high_achiever, levels = c(0,1)),
  estimate = pred_rf_class
)

rf_accuracy <- yardstick::accuracy(rf_df, truth = truth, estimate = estimate)$.estimate
rf_precision <- yardstick::precision(rf_df, truth = truth, estimate = estimate)$.estimate
rf_recall <- yardstick::recall(rf_df, truth = truth, estimate = estimate)$.estimate
rf_f1 <- yardstick::f_meas(rf_df, truth = truth, estimate = estimate)$.estimate

roc_rf <- roc(test_class$high_achiever, prob_rf_class[,2])
auc_rf <- auc(roc_rf)

# XGBoost
xgb_metrics_obj <- yardstick::metrics(bind_cols(truth = test_class$high_achiever, estimate = as.factor(xgb_class), prob = pred_xgb_class), truth, estimate, prob)
roc_xgb <- roc(as.numeric(test_class$high_achiever), pred_xgb_class)
auc_xgb <- auc(roc_xgb)

xgb_df <- tibble(
  truth = factor(test_class$high_achiever, levels = c(0,1)),
  estimate = as.factor(xgb_class)
)

xgb_accuracy <- yardstick::accuracy(xgb_df, truth = truth, estimate = estimate)$.estimate
xgb_precision <- yardstick::precision(xgb_df, truth = truth, estimate = estimate)$.estimate
xgb_recall <- yardstick::recall(xgb_df, truth = truth, estimate = estimate)$.estimate
xgb_f1 <- yardstick::f_meas(xgb_df, truth = truth, estimate = estimate)$.estimate

roc_xgb <- roc(test_class$high_achiever, pred_xgb_class)
auc_xgb <- auc(roc_xgb)

```

```{r}
# Compile results in a table
classification_metrics <- data.frame(
  Model = c("Logistic Regression", "Random Forest", "XGBoost"),
  Accuracy = c(logit_accuracy, rf_accuracy, xgb_accuracy),
  Precision = c(logit_precision, rf_precision, xgb_precision),
  Recall = c(logit_recall, rf_recall, xgb_recall),
  F1 = c(logit_f1, rf_f1, xgb_f1),
  AUC = c(auc_logit, auc_rf, auc_xgb)
)

print(classification_metrics)
classification_metrics %>%
  kable(format = "html", digits = 3, caption = "Classification Metrics for Models") %>%
  kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover", "condensed"))

```

------------------------------------------------------------------------

------------------------------------------------------------------------

```         
```

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

```{r}
1 + 1
```
